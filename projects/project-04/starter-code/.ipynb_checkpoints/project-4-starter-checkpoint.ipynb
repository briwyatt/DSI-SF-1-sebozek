{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with stumbleupon data\n",
    "\n",
    "Project 4 has been changed since scraping was untenable. The project now focuses on the stumbleupon kaggle dataset. For more information on this dataset, [check out the website here](https://www.kaggle.com/c/stumbleupon).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Data Dictionary](#datadict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the dataset\n",
    "\n",
    "This is the only part completed for you.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "su = pd.read_csv('../dataset/evergreen.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean up/examine your data\n",
    "\n",
    "Some of the columns may have values that need changing or that are of the wrong type. There could also be columns that aren't very useful.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "su.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "<a id=\"datadict\"></a>\n",
    "\n",
    "|Column Name|Description|Variable Type|\n",
    "|---|---|--|\n",
    "|url|URL of the recommended website|Categorical|\n",
    "|urlid|Unique StumbleUpon ID assigned to the URL|Ordinal|\n",
    "|boilerplate|JSON file containing the text of the title and the text of the body|Categorical|\n",
    "|alchemy_category|Category of the website assigned through AlchemyAPI|Categorical|\n",
    "|alchemy_category_score|Score from 1(best) to 0(worst) of the confidence of the AlchemyAPI in assigning the category|Interval|\n",
    "|avglinksize|Mean number of words that appear in all the links present on the wepsite|Cardinal|\n",
    "|commonLinkRatio_(1-4)| The number of links sharing at least one word in common with x other links divided by total number of links|Interval|\n",
    "|compression_ratio|Ratio of compressed size of website to uncompressed size (using gzip)|Interval|\n",
    "|embed_ratio| Ratio of how many times HTML embed element appears relative to other elements|Interval|\n",
    "|frameBased|Whether or not a website is using a frameset markup(1) or a body(0)|Categorical|\n",
    "|frameTagRatio|Ratio of frames to markup|Interval|\n",
    "|hasDomainLink|Whether(1) or not(0) the website has a link to a domain|Categorical|\n",
    "|html_ratio|How many tags are present to total text span on the website|Interval|\n",
    "|image_ratio|Ratio of <img> tags to total text span on the website|Interval|\n",
    "|is_news|Whether(1) or not(0) the website is categorized as news|Categorical|\n",
    "|lengthyLinkDomain|Whether(1) or not(0) at least three links contain >30 characters|Categorical|\n",
    "|linkwordscore|Ratio of words on page to the hyperlink text|Interval|\n",
    "|news_front_page|Whether(1) or not(0) the news is considered significant 'front page'|Categorical|\n",
    "|non_markup_alphanum_characters|Total number of characters in the text of the website|Ordinal|\n",
    "|numberOfLinks|Count of how many links are present|Ordinal\n",
    "|numwords_in_url|Count of words in the URL|Ordinal|\n",
    "|parametrizedLinkRatio|Ratio of links with an event on the click or additonal parameter to all other links|Interval|\n",
    "|spelling_errors_ratio|Ratio of words classified as misspelled to all text present|Interval|\n",
    "|label| **TARGET** Whether(1) or not(0) the website is considered 'evergreen'|Categorical|\n",
    "\n",
    "* What makes evergreen news stories? Are there any?\n",
    "* Does AlchemyAPI score play into whether it is evergreen?\n",
    "* Is FrameSet or Body more likely to be evergreen?\n",
    "* Are there evergreen front page news stories? What text do they contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7395 entries, 0 to 7394\n",
      "Data columns (total 27 columns):\n",
      "url                               7395 non-null object\n",
      "urlid                             7395 non-null int64\n",
      "boilerplate                       7395 non-null object\n",
      "alchemy_category                  7395 non-null object\n",
      "alchemy_category_score            7395 non-null object\n",
      "avglinksize                       7395 non-null float64\n",
      "commonlinkratio_1                 7395 non-null float64\n",
      "commonlinkratio_2                 7395 non-null float64\n",
      "commonlinkratio_3                 7395 non-null float64\n",
      "commonlinkratio_4                 7395 non-null float64\n",
      "compression_ratio                 7395 non-null float64\n",
      "embed_ratio                       7395 non-null float64\n",
      "framebased                        7395 non-null int64\n",
      "frameTagRatio                     7395 non-null float64\n",
      "hasDomainLink                     7395 non-null int64\n",
      "html_ratio                        7395 non-null float64\n",
      "image_ratio                       7395 non-null float64\n",
      "is_news                           7395 non-null object\n",
      "lengthyLinkDomain                 7395 non-null int64\n",
      "linkwordscore                     7395 non-null int64\n",
      "news_front_page                   7395 non-null object\n",
      "non_markup_alphanum_characters    7395 non-null int64\n",
      "numberOfLinks                     7395 non-null int64\n",
      "numwords_in_url                   7395 non-null int64\n",
      "parametrizedLinkRatio             7395 non-null float64\n",
      "spelling_errors_ratio             7395 non-null float64\n",
      "label                             7395 non-null int64\n",
      "dtypes: float64(12), int64(9), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "su.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Through looking at the description of the variables present, certain items related to the URL are likely not important to the regression at hand. Because of the nature of stumbleupon, the URL itself and associated identifiers are likely not that important*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "su_log = su[\n",
    "    [\n",
    "'label',\n",
    "'spelling_errors_ratio',\n",
    "'alchemy_category',\n",
    "'alchemy_category_score',\n",
    "'framebased',\n",
    "'html_ratio',\n",
    "'image_ratio',\n",
    "'is_news',\n",
    "'news_front_page',\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use statsmodels' logistic regression function to look at variable significance\n",
    "\n",
    "The **`import statsmodels.formula.api as smf`** code below gives us access to a statsmodels api that can run logistic regressions using patsy-style formulas.\n",
    "\n",
    "Ex:\n",
    "\n",
    "```python\n",
    "formula = 'target ~ var1 + var2 + C(var3) -1'\n",
    "logreg = smf.logit(formula, data=data)\n",
    "logreg_results = logreg.fit()\n",
    "print logreg_results.summary()\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import appropriate pacakges\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Formula\n",
    "formula = 'label ~ html_ratio + image_ratio + embed_ratio + frameTagRatio +parametrizedLinkRatio + spelling_errors_ratio - 1' # -1 used to remove the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logr = smf.logit(formula, data=su)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.673377\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "logr_result = logr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   No. Observations:                 7395\n",
      "Model:                          Logit   Df Residuals:                     7389\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Thu, 12 May 2016   Pseudo R-squ.:                 0.02802\n",
      "Time:                        08:06:12   Log-Likelihood:                -4979.6\n",
      "converged:                       True   LL-Null:                       -5123.2\n",
      "                                        LLR p-value:                 5.799e-60\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "-----------------------------------------------------------------------------------------\n",
      "html_ratio                3.0495      0.245     12.458      0.000         2.570     3.529\n",
      "image_ratio              -0.0414      0.020     -2.121      0.034        -0.080    -0.003\n",
      "embed_ratio               0.0846      0.087      0.967      0.333        -0.087     0.256\n",
      "frameTagRatio           -10.7672      0.705    -15.271      0.000       -12.149    -9.385\n",
      "parametrizedLinkRatio     0.2122      0.127      1.667      0.096        -0.037     0.462\n",
      "spelling_errors_ratio    -0.9696      0.320     -3.028      0.002        -1.597    -0.342\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print logr_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Run a logistic regression predicting evergreen from the numeric columns\n",
    "\n",
    "And print out the results as shown in the example above.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formula = 'label ~ alchemy_category_score + avglinksize + compression_ratio + embed_ratio + frameTagRatio + html_ratio + image_ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = smf.logit(formula, data=su)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = logreg.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Run a logistic regression predicting evergreen from the numeric columns and a categorical variable of alchemy_category\n",
    "\n",
    "And print out the results as shown in the example.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use sklearn to cross-validate the accuracy of the model above\n",
    "\n",
    "Normalize the numeric and categorical columns of the predictor matrix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gridsearch regularization parameters for logistic regression\n",
    "\n",
    "Find the best regularization type (Ridge, Lasso) across a set of regularization strengths.\n",
    "\n",
    "[NOTE: C is the inverse of the regularization strength. Lower C values are stronger regularization. Having a C higher than 1 will significantly slow down the search. I'm not particularly interested in values over 1, since this is the default regularization strength in LogisticRegression.]\n",
    "\n",
    "**After you find the best set of parameters, build a Logistic Regression with those parameters and crossvalidate the score.**\n",
    "\n",
    "[NOTE 2: to run Lasso regularization the solver should be `'liblinear'`]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gridsearch neighbors for kNN\n",
    "\n",
    "Find the best number of neighbors with your predictors to predict the `label` target variable.\n",
    "\n",
    "Start by bulding a kNN model with a set number of neighbors, then use gridsearch to run through a series of neighbors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Choose a new target from alchemy_category to predict with logistic regression\n",
    "\n",
    "**Ideally your category choice will have a small fraction of the total rows, but not TOO small!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "?                     2342\n",
       "recreation            1229\n",
       "arts_entertainment     941\n",
       "business               880\n",
       "health                 506\n",
       "sports                 380\n",
       "culture_politics       343\n",
       "computer_internet      296\n",
       "science_technology     289\n",
       "gaming                  76\n",
       "religion                72\n",
       "law_crime               31\n",
       "unknown                  6\n",
       "weather                  4\n",
       "Name: alchemy_category, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "su['alchemy_category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Chose your target category, create the Y vector, and check the fraction of instances\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "su['is_culture'] = su['alchemy_category'].apply(lambda x: 1 if x == 'cutlure_politics' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "su['alchemy_category'] = su['alchemy_category'].apply(lambda x: np.NaN if x == '?' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Use patsy to create an X matrix of the numeric predictors and all two-way interactions between them\n",
    "\n",
    "Ex:\n",
    "\n",
    "```python\n",
    "import patsy\n",
    "\n",
    "formula_interactions = '~ (var1 + var2 + var3)**2 -1'\n",
    "X_interactions = patsy.dmatrix(formula_interactions, data=data\n",
    "```\n",
    "\n",
    "Get the column names from the `design_info` property of the patsy X matrix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Normalize the predictor matrix columns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Gridsearch a logistic regression to predict accuracy on your new target from the interaction predictors\n",
    "\n",
    "Include Ridge and Lasso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Build a logistic regression with the optimal parameters, and look at the coefficients\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Gridsearch parameters for a logistic regression with the same target and predictors, but score based on precision rather than accuracy\n",
    "\n",
    "Look at the documentation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [BONUS] 8. Build models predicting from words\n",
    "\n",
    "This is a bit of the NLP we covered in the pipeline lecture!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Choose 'body' or 'title' from the boilerplate to be the basis of your word predictors\n",
    "\n",
    "You will need to parse the json from the boilerplate field.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Use CountVectorizer to create your predictor matrix from the string column\n",
    "\n",
    "It is up to you what range of ngrams and features, and whether or not you want the columns binary or counts.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Gridsearch a logistic regression predicting accuracy of your chosen target category from word predictor matrix\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Do the same as above, but score the gridsearch based on precision rather than accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Build a logistic regression with optimal precision categories\n",
    "\n",
    "Print out the top 20 or 25 word features as ranked by their coefficients.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
